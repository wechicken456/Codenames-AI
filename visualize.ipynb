{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff5174ca-f308-4d94-8e10-19cd68bd6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0a22ce-35bd-4ff3-afe3-e2076cf02da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./SWOW-EN.R100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43e969ea-8933-432a-bb75-c1db8fc67365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75         1\n",
      "86         1\n",
      "91         1\n",
      "107        1\n",
      "112        2\n",
      "          ..\n",
      "1196965    1\n",
      "1197013    1\n",
      "1197021    1\n",
      "1197025    3\n",
      "1197076    1\n",
      "Name: R1, Length: 45586, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[~df[\"R1\"].isna()]\n",
    "r1 = df[\"R1\"]\n",
    "\n",
    "l = r1.apply(lambda x: len(x.split(\" \")))\n",
    "t = l.apply(lambda x : x - 1)\n",
    "t = t[t > 0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ff676e44-8a98-444d-a6e9-2a7a2e24490d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>participantID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>nativeLanguage</th>\n",
       "      <th>country</th>\n",
       "      <th>education</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cue</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>135</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>Ma</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-08-14 22:08:12</td>\n",
       "      <td>hang</td>\n",
       "      <td>hang-dei swerangen/woo</td>\n",
       "      <td>gallows</td>\n",
       "      <td>coat hanger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>183</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>Fe</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-08-14 22:28:48</td>\n",
       "      <td>bring</td>\n",
       "      <td>to me</td>\n",
       "      <td>wine</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>202</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>Fe</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-08-14 22:28:48</td>\n",
       "      <td>trouble</td>\n",
       "      <td>oh oh</td>\n",
       "      <td>naughty</td>\n",
       "      <td>boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>203</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>Fe</td>\n",
       "      <td>United States</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-08-14 22:29:31</td>\n",
       "      <td>much</td>\n",
       "      <td>a lot</td>\n",
       "      <td>very</td>\n",
       "      <td>some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>216</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>Fe</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-08-14 22:33:38</td>\n",
       "      <td>such</td>\n",
       "      <td>a nice day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196965</th>\n",
       "      <td>1196965</td>\n",
       "      <td>1228036</td>\n",
       "      <td>1228037</td>\n",
       "      <td>1500360</td>\n",
       "      <td>130328</td>\n",
       "      <td>57</td>\n",
       "      <td>Fe</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-01-06 08:06:19</td>\n",
       "      <td>first</td>\n",
       "      <td>number one</td>\n",
       "      <td>this one</td>\n",
       "      <td>primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197013</th>\n",
       "      <td>1197013</td>\n",
       "      <td>1228084</td>\n",
       "      <td>1228085</td>\n",
       "      <td>1500436</td>\n",
       "      <td>130332</td>\n",
       "      <td>61</td>\n",
       "      <td>Ma</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-07 04:29:38</td>\n",
       "      <td>post</td>\n",
       "      <td>guard duty</td>\n",
       "      <td>mail</td>\n",
       "      <td>fence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197021</th>\n",
       "      <td>1197021</td>\n",
       "      <td>1228092</td>\n",
       "      <td>1228093</td>\n",
       "      <td>1500585</td>\n",
       "      <td>130344</td>\n",
       "      <td>33</td>\n",
       "      <td>Fe</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-08 18:01:51</td>\n",
       "      <td>actually</td>\n",
       "      <td>in truth</td>\n",
       "      <td>truthfully</td>\n",
       "      <td>basically</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197025</th>\n",
       "      <td>1197025</td>\n",
       "      <td>1228096</td>\n",
       "      <td>1228097</td>\n",
       "      <td>1500584</td>\n",
       "      <td>130344</td>\n",
       "      <td>33</td>\n",
       "      <td>Fe</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-08 18:01:51</td>\n",
       "      <td>dig</td>\n",
       "      <td>dig into the earth</td>\n",
       "      <td>hole</td>\n",
       "      <td>Divot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197076</th>\n",
       "      <td>1197076</td>\n",
       "      <td>1228151</td>\n",
       "      <td>1228152</td>\n",
       "      <td>1500675</td>\n",
       "      <td>130349</td>\n",
       "      <td>35</td>\n",
       "      <td>Fe</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Italy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-09 09:05:51</td>\n",
       "      <td>redo</td>\n",
       "      <td>do again</td>\n",
       "      <td>do better</td>\n",
       "      <td>second time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45586 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         level_0    index  Unnamed: 0       id  participantID  age gender  \\\n",
       "75            75       75          76      135             11   36     Ma   \n",
       "86            86       86          87      183             15   35     Fe   \n",
       "91            91       91          92      202             15   35     Fe   \n",
       "107          107      107         108      203             16   39     Fe   \n",
       "112          112      113         114      216             18   40     Fe   \n",
       "...          ...      ...         ...      ...            ...  ...    ...   \n",
       "1196965  1196965  1228036     1228037  1500360         130328   57     Fe   \n",
       "1197013  1197013  1228084     1228085  1500436         130332   61     Ma   \n",
       "1197021  1197021  1228092     1228093  1500585         130344   33     Fe   \n",
       "1197025  1197025  1228096     1228097  1500584         130344   33     Fe   \n",
       "1197076  1197076  1228151     1228152  1500675         130349   35     Fe   \n",
       "\n",
       "        nativeLanguage        country  education           created_at  \\\n",
       "75           Australia      Australia        NaN  2011-08-14 22:08:12   \n",
       "86           Australia      Australia        NaN  2011-08-14 22:28:48   \n",
       "91           Australia      Australia        NaN  2011-08-14 22:28:48   \n",
       "107      United States      Australia        NaN  2011-08-14 22:29:31   \n",
       "112          Australia      Australia        NaN  2011-08-14 22:33:38   \n",
       "...                ...            ...        ...                  ...   \n",
       "1196965    New Zealand    New Zealand        4.0  2018-01-06 08:06:19   \n",
       "1197013  United States  United States        5.0  2018-01-07 04:29:38   \n",
       "1197021  United States  United States        5.0  2018-01-08 18:01:51   \n",
       "1197025  United States  United States        5.0  2018-01-08 18:01:51   \n",
       "1197076        Italian          Italy        5.0  2018-01-09 09:05:51   \n",
       "\n",
       "              cue                      R1          R2           R3  \n",
       "75           hang  hang-dei swerangen/woo     gallows  coat hanger  \n",
       "86          bring                   to me        wine       cheese  \n",
       "91        trouble                   oh oh     naughty         boys  \n",
       "107          much                   a lot        very         some  \n",
       "112          such              a nice day         NaN          NaN  \n",
       "...           ...                     ...         ...          ...  \n",
       "1196965     first              number one    this one      primary  \n",
       "1197013      post              guard duty        mail        fence  \n",
       "1197021  actually                in truth  truthfully    basically  \n",
       "1197025       dig      dig into the earth        hole        Divot  \n",
       "1197076      redo                do again   do better  second time  \n",
       "\n",
       "[45586 rows x 15 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[t.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6f390e3-54c9-4a00-a498-465c35d85976",
   "metadata": {},
   "outputs": [],
   "source": [
    "swow_rel_forward = \"forwardassociated\"\n",
    "swow_rel_bidirectional = \"bidirectionalassociated\"\n",
    "swow_rel_backward = \"backwardassociated\"\n",
    "\n",
    "\n",
    "relation_groups = [\n",
    "  swow_rel_forward,\n",
    "  swow_rel_bidirectional \n",
    "]\n",
    "\n",
    "merged_relations = [\n",
    "   swow_rel_forward,\n",
    "   swow_rel_bidirectional,\n",
    "]\n",
    "\n",
    "relation_groups_1rel= [\n",
    "  swow_rel_forward,\n",
    "]\n",
    "\n",
    "merged_relations_1rel = [\n",
    "   swow_rel_forward,\n",
    "]\n",
    "\n",
    "def check_path(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "        \n",
    "class SWOW(object):\n",
    "    def __init__(self, swow_file, output_csv_path=\"./data/swow/swow_associations.csv\",  output_vocab_path=\"./data/swow/swow_vocab.csv\", kg_name='swow', word_pair_freq=1):\n",
    "        self.kg_name = kg_name \n",
    "        self.swow_data = self.load_swow_en(swow_file)\n",
    "        self.swow_cue_responses, self.concepts = self.forward_associations(self.swow_data, word_pair_freq, unify_nodes=True)\n",
    "        self.swow_cue_responses_relation = self.add_relations(self.swow_cue_responses)\n",
    "        if output_csv_path is not None:\n",
    "            self.write_cues(self.swow_cue_responses.keys(), output_path=\"./data/swow/swow_cues.csv\")\n",
    "            self.write_forward_associations_relation(self.swow_cue_responses_relation, output_csv_path, output_vocab_path)\n",
    "\n",
    "    def load_swow_en(self, input_file):\n",
    "        cues, R1, R2, R3 = list(),list(),list(),list()\n",
    "        reader =csv.DictReader(open(input_file))\n",
    "        for row in reader:\n",
    "            cues.append(row['cue'].lower())\n",
    "            R1.append(row['R1'].lower())\n",
    "            R2.append( row['R2'].lower())\n",
    "            R3.append( row['R3'].lower())\n",
    "\n",
    "        swow_data = list(zip(cues, R1, R2, R3))\n",
    "        print(\"Loaded %d lines from %s\"%(len(cues),input_file))\n",
    "        return swow_data\n",
    "\n",
    "    def unify_sw_nodes(self, node):\n",
    "        '''unify entity format with ConceptNet5.6, in which entity is concatenated by words with _'''\n",
    "        '''keep words concatenated by -, like 'self-esteem', 'self-important' '''\n",
    "        node_list_raw = re.split(' ', node)\n",
    "\n",
    "        blacklist = ['a'] # a club,\n",
    "        if len(node_list_raw)>1 and node_list_raw[0] in blacklist:\n",
    "            node_list_raw.remove(node_list_raw[0])\n",
    "\n",
    "        if node_list_raw[0].startswith(\"-\"): #-free (gluten -free)\n",
    "            node_list_raw[0] = node_list_raw[0][1:]\n",
    "\n",
    "        if node_list_raw[0].startswith(\"_\"): #_position\n",
    "            node_list_raw[0] = node_list_raw[0][1:]\n",
    "\n",
    "         #cases: beard_-_eyebrows_-_mustache,  bearskin___________disrobe_________reveal, bear__wine\n",
    "        node_list =  []\n",
    "        for node in node_list_raw:\n",
    "            node = node.replace(\"_-_\", \"\")\n",
    "            node = node.replace(\"___________\", \"\")\n",
    "            node = node.replace(\"__\", \"\")\n",
    "            node = node.replace(\"_\", \"\")\n",
    "            node = node.replace(\"__\",\"\")\n",
    "            node = node.replace(\"__\",\"\")\n",
    "            #node = node.replace(\"-\", \"_\") #real text contains -, eg, self-important\n",
    "            if node: # if not empty string, \"- Johnson wife of lyndon\"\n",
    "                node_list.append(node)\n",
    "\n",
    "        node_len = len(node_list)\n",
    "        if node_len >0:\n",
    "            node_phrase = \"_\".join(node_list)\n",
    "            #if not en_dict.check(node_phrase):\n",
    "            #   print(node_phrase)\n",
    "            return node_phrase, node_len\n",
    "        else: #filter empty node\n",
    "            #print(\"empty node: {}\".format(node_list_raw))\n",
    "            return None, None\n",
    "\n",
    "    def forward_associations(self, swow_data, word_pair_freq, unify_nodes=False):\n",
    "        cue_responses={}\n",
    "        concepts=set()\n",
    "        phrase_seen = dict()\n",
    "        for i, (cue, r1, r2, r3) in enumerate(swow_data):\n",
    "\n",
    "            cue = cue.lower()\n",
    "            if unify_nodes:\n",
    "                phrase_ori = cue\n",
    "                cue, phrase_len = self.unify_sw_nodes(cue)\n",
    "                if phrase_len is None:\n",
    "                    continue\n",
    "                if phrase_len >1:\n",
    "                    if cue not in phrase_seen:\n",
    "                        phrase_seen[cue]=[phrase_ori]\n",
    "                    else:\n",
    "                        phrase_seen[cue].extend([phrase_ori])\n",
    "\n",
    "            for r in [r1, r2, r3]:\n",
    "                #if cue not in cue_responses.keys() and r!=\"NA\" or \"na\":\n",
    "                r = r.lower()\n",
    "\n",
    "                if r=='na' or r == \"nan\": continue\n",
    "                if cue == r: continue #about 1000, e.g., read, aimless, sheen, elbows\n",
    "\n",
    "                if unify_nodes:\n",
    "                    phrase_ori = r\n",
    "                    r, phrase_len = self.unify_sw_nodes(r)\n",
    "\n",
    "                    if phrase_len is None:\n",
    "                        continue\n",
    "\n",
    "                    if phrase_len >1:\n",
    "                        if r not in phrase_seen:\n",
    "                            phrase_seen[r]=[phrase_ori]\n",
    "                        else:\n",
    "                            phrase_seen[r].extend([phrase_ori])\n",
    "\n",
    "                if not cue.replace(\"_\", \"\").replace(\"-\", \"\").replace(\" \",\"\").replace(\"''\",\"\").isalpha():\n",
    "                    #print(\"cue: {}\".format(cue))\n",
    "                    continue\n",
    "                if not r.replace(\"_\", \"\").replace(\"-\", \"\").replace(\" \",\"\").replace(\"''\",\"\").isalpha():\n",
    "                    #print(\"response: {}\".format(r))\n",
    "                    continue\n",
    "\n",
    "                if cue in string.punctuation or r in string.punctuation:\n",
    "                    print(f\"dirty data: {cur}, {r}\")\n",
    "                    continue\n",
    "\n",
    "                if cue not in cue_responses.keys() :\n",
    "                    cue_responses[cue]={r:1}\n",
    "                    concepts.add(cue)\n",
    "                    concepts.add(r)\n",
    "                else:\n",
    "                    cue_responses = self.add_elements(cue_responses, cue, r)\n",
    "                    concepts.add(r)\n",
    "\n",
    "\n",
    "        num_swow_triplets = sum([len(x) for x in cue_responses.values()])\n",
    "        print(\"Number of original triplets in SWOW is {}\".format(num_swow_triplets))\n",
    "        if word_pair_freq >1:\n",
    "            cue_responses = self.filter_frequency(cue_responses, word_pair_freq)\n",
    "            cut_down_num = num_swow_triplets - sum([len(x) for x in cue_responses.values()])\n",
    "            print(\"Cutting down {} triplets whose wordpair_frequency<{}\".format(cut_down_num, word_pair_freq))\n",
    "\n",
    "            num_swow_triplets = sum([len(x) for x in cue_responses.values()])\n",
    "            print(\"Number of original triplets in SWOW is {} (after cutting down)\".format(num_swow_triplets))\n",
    "\n",
    "        return cue_responses, concepts\n",
    "\n",
    "    def add_relations(self, cue_responses):\n",
    "        cue_responses_relation= list() # bugfix: use list() instead of set(), guaranteeing vocab order to be the same for everytime \n",
    "        count_bi = 0\n",
    "        count_fw = 0\n",
    "        for cue, vs in cue_responses.items():\n",
    "            for response, freq in vs.items():\n",
    "                rel_forward = swow_rel_forward.lower()\n",
    "                cue_responses_relation.append((rel_forward, cue, response, freq))\n",
    "                count_fw +=1\n",
    "\n",
    "                if self.kg_name == 'swow':\n",
    "                    if response in cue_responses and cue in cue_responses[response]:\n",
    "                        rel_bidirection = swow_rel_bidirectional.lower()\n",
    "                        cue_responses_relation.append((rel_bidirection, cue, response, freq))\n",
    "                        count_bi+=1\n",
    "        print(\"Add {} forward association triples\".format(count_fw))\n",
    "        print(\"Add {} bi-directional association triples\".format(count_bi))\n",
    "        return cue_responses_relation\n",
    "\n",
    "    def write_cues(self, cues, output_path):\n",
    "        check_path(output_path)\n",
    "        with open(output_path, 'w') as fout:\n",
    "            for cue in cues:\n",
    "              fout.write(cue+'\\n')\n",
    "        print(\"write {} {} cues\".format(output_path, len(cues)))\n",
    "\n",
    "    def write_forward_associations_relation(self, cue_responses_relation,\n",
    "                    output_csv_path, output_vocab_path):\n",
    "        '''\n",
    "        input: (rel, heat, tail, freq)\n",
    "        '''\n",
    "        cpnet_vocab = []\n",
    "        # cpnet_vocab.append(PAD_TOKEN)\n",
    "\n",
    "        concepts_seen = set()\n",
    "        check_path(output_csv_path)\n",
    "        fout = open(output_csv_path, \"w\", encoding=\"utf8\")\n",
    "        # cue_responses_relation = list(cue_responses_relation)\n",
    "        cnt=0\n",
    "        for (rel, head, tail, freq) in cue_responses_relation:\n",
    "            fout.write('\\t'.join([rel, head, tail, str(freq)]) + '\\n')\n",
    "            cnt+=1\n",
    "            for w in [head, tail]:\n",
    "                if w not in concepts_seen:\n",
    "                    concepts_seen.add(w)\n",
    "                    cpnet_vocab.append(w)\n",
    "\n",
    "        check_path(output_vocab_path)\n",
    "        with open(output_vocab_path, 'w') as fout:\n",
    "            for word in cpnet_vocab:\n",
    "                fout.write(word + '\\n')\n",
    "\n",
    "        print('extracted {} triples to {}'.format(cnt, output_csv_path))\n",
    "        print('extracted {} concpet vocabulary to {}'.format(len(cpnet_vocab), output_vocab_path))\n",
    "        print()\n",
    "\n",
    "        return cpnet_vocab\n",
    "\n",
    "\n",
    "    def add_elements_dict2d(self,outter, outter_key, inner_key,value):\n",
    "        if outter_key not in outter.keys():\n",
    "            outter.update({outter_key:{inner_key:value}})\n",
    "        else:\n",
    "            outter[outter_key].update({inner_key:value})\n",
    "        return outter\n",
    "\n",
    "    def add_elements(self,outter, outter_key, inner_key):\n",
    "        if inner_key not in outter[outter_key].keys():\n",
    "            outter[outter_key].update({inner_key:1})\n",
    "        else:\n",
    "            outter[outter_key][inner_key]+=1\n",
    "        return outter\n",
    "\n",
    "    def filter_frequency(self,cue_responses, word_pair_freq=2):\n",
    "        new_cue_responses={}\n",
    "\n",
    "        for i, (cue,responses) in enumerate(tqdm(cue_responses.items())):\n",
    "            for response,frequency in responses.items():\n",
    "                if response == 'NA' or response=='na': continue\n",
    "\n",
    "                if frequency >= word_pair_freq:\n",
    "                    self.add_elements_dict2d(outter=new_cue_responses,\n",
    "                                        outter_key=cue,\n",
    "                                        inner_key=response,\n",
    "                                        value=frequency)\n",
    "        return new_cue_responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8998ca87-fe8a-485c-af7f-64f2516d40c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1228200 lines from ./SWOW-EN.R100.csv\n",
      "Number of original triplets in SWOW is 1384533\n",
      "Add 1384533 forward association triples\n",
      "Add 209008 bi-directional association triples\n",
      "write ./data/swow/swow_cues.csv 12274 cues\n",
      "extracted 1593541 triples to ./data/swow/swow_associations.csv\n",
      "extracted 124626 concpet vocabulary to ./data/swow/swow_vocab.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SWOW at 0x792e06fa2660>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SWOW(\"./SWOW-EN.R100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a0ca6-4c74-415a-b13d-4301c5bfaeef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e249d7a-9907-43fc-af39-9f2ff13878ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "94b06a93-2c7f-4532-986a-a83587f7f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./data/swow/swow_associations.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1473ffeb-3d41-43f9-8cd0-58cd7cf4af1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>associtation_type</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500013</th>\n",
       "      <td>forwardassociated</td>\n",
       "      <td>star</td>\n",
       "      <td>moon</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500014</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>star</td>\n",
       "      <td>moon</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              associtation_type word1 word2  count\n",
       "500013        forwardassociated  star  moon      7\n",
       "500014  bidirectionalassociated  star  moon      7"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns = {\"forwardassociated\": \"associtation_type\", \"although\": \"word1\", \"nevertheless\": \"word2\", \"3\": \"count\"})\n",
    "df[(df[\"word1\"] == \"star\") &  (df[\"word2\"] == \"moon\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aeedbdaf-eec8-4194-bf70-e3656f63044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./swow.bidirectionalassociated.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "821c07d0-988d-4c13-9d73-d904682bb462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidirectionalassociated</th>\n",
       "      <th>although</th>\n",
       "      <th>nevertheless</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>although</td>\n",
       "      <td>yet</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>although</td>\n",
       "      <td>but</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>although</td>\n",
       "      <td>though</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>although</td>\n",
       "      <td>however</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>although</td>\n",
       "      <td>instead</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209002</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>ew</td>\n",
       "      <td>tasteless</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209003</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>ew</td>\n",
       "      <td>puke</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209004</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>ew</td>\n",
       "      <td>snot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209005</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>lipid</td>\n",
       "      <td>cholesterol</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209006</th>\n",
       "      <td>bidirectionalassociated</td>\n",
       "      <td>lipid</td>\n",
       "      <td>membrane</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209007 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bidirectionalassociated  although nevertheless   3\n",
       "0       bidirectionalassociated  although          yet  12\n",
       "1       bidirectionalassociated  although          but  36\n",
       "2       bidirectionalassociated  although       though   8\n",
       "3       bidirectionalassociated  although      however  22\n",
       "4       bidirectionalassociated  although      instead   5\n",
       "...                         ...       ...          ...  ..\n",
       "209002  bidirectionalassociated        ew    tasteless   1\n",
       "209003  bidirectionalassociated        ew         puke   1\n",
       "209004  bidirectionalassociated        ew         snot   1\n",
       "209005  bidirectionalassociated     lipid  cholesterol  11\n",
       "209006  bidirectionalassociated     lipid     membrane   3\n",
       "\n",
       "[209007 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "775d1a27-8067-45da-955c-774485d39eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./wikipedia_freq.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.split(\" \") for line in lines]\n",
    "    wiki_freq = dict(lines)\n",
    "    wiki_freq = {k: int(v) for k, v in wiki_freq.items()}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8174f63-977e-4817-b6a9-8e172b9d9676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce32631-7189-49d7-acd5-214f48e8336a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d107df-893a-4126-b718-b64c78992f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff9cbb-1918-4637-9f71-46873bb1ea0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e954c3-d3e9-4506-8aa8-5efe79e8b7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b515465-49b7-4ac3-892b-b4fd3d3f2dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed15f90-05eb-49f2-b5e0-2bcb30ad46a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e3e9d-6bf7-47c3-91af-d1dc4b971911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
