#!/usr/bin/env python
# coding: utf-8

# In[9]:


import sys
from openai import OpenAI
from dotenv import load_dotenv
import os
import time
from sentence_transformers import SentenceTransformer
import json
import asyncio
from nltk.corpus import wordnet as wn

from .codemaster import Codemaster
from .LLM.codemaster import LLM
from .LLM.codemaster_2 import LLM2
from .conceptnet.conceptnet import ConceptNet
from .annoy_index.annoy import Annoy

from nltk.stem import WordNetLemmatizer
import lemminflect
import json
import spacy
import numpy as np
from itertools import combinations
from sklearn.metrics.pairwise import cosine_similarity


# In[6]:


load_dotenv()
openai_api_key = os.environ.get("OPENAI_API_KEY")
nlp = spacy.load("en_core_web_trf")


# In[4]:


debug = True


# In[8]:


allowed_word_types = [
    "ADJ",	
    "ADV",
    "INTJ",	
    "NOUN",
    "PROPN",	
    "VERB"
]

lemmatizer = WordNetLemmatizer()
def get_word_lemma(word : str, pos_hint : str = None) -> str:
    """
    Gets the lemma of a single word without sentence context using NLTK's WordNetLemmatizer.
    pos_hint can be 'n' (noun), 'v' (verb), 'a' (adjective), 'r' (adverb).
    Defaults to 'n' if no hint is given.
    """
    return lemmatizer.lemmatize(word.lower(), pos=pos_hint) if pos_hint else lemmatizer.lemmatize(word.lower())

def get_all_possible_lemmas(word: str) -> list[str]:
    res = []
    for hint in ["v", "n", "a", "r", "s"]:
        res.append(get_word_lemma(word, hint))
    return res

def get_all_inflections(word : str) -> list[str]:
    inflections = lemminflect.getAllInflections(word)
    res = []
    for _, i in inflections.items():
        res += list(i)
    return res

def sync_wrapper(coro):
    loop = asyncio.get_event_loop()
    return loop.run_until_complete(coro)


def format_llm_selection_prompt(team, enemy, red, blue, civilian, assassin, move_history, clue_candidates):
    system_prompt = f"""
You are a human that plays the game Codenames using common knowledge, clarity, and reasoning. 

**Task:**
You are given the current state of the game and a list of possible clues (not in any particular order) generated by a teammate. Each clue is intended to target a specific subset of your team's words. Your job is to **select the best clue to give to your guessers**, based on the provided principles of clue quality and safety.

**Game State:**
- Your team: {team}
- Your remaining words: {red if team.lower() == 'red' else blue}
- Enemy remaining words: {blue if team.lower() == 'red' else red}
- Civilian remaining words: {civilian}
- Assassin word: {assassin}

**Move History:**
{move_history}

**Candidate Clues:**
Each candidate clue was automatically generated. All clues are single English words and attempt to connect semantically with the listed target words.
The clues are listed in no particular order.

"""

    for i, (score, clue, subset) in enumerate(clue_candidates):
        system_prompt += f"{i+1}. Clue: \"{clue}\" — Targets: {subset} — Number of targets: {len(subset)}\n"

    system_prompt += f"""

**Your Clue Selection Strategy:**

1. **Clarity and Immediate Understandability**
   - The clue must connect strongly and obviously to its target words.
   - Avoid niche or obscure or indirect associations.

2. **Strict Rule Compliance**
   - Clue must not be a form or compound of any word on the board.
   - Must be a single word (not a phrase or name).
   - Must not rely on uncommon or culturally niche knowledge.

3. **Avoiding the Assassin Word**
   - If **any clue even loosely relates** to the assassin word, it must be disqualified.

4. **Minimizing Risk**
   - Prefer clues with minimal semantic overlap with enemy or civilian words.

5. **Think like a human player**
   - Avoid clues that require expert knowledge or unusual interpretations.

6. **Subset Size Awareness**
   - Bigger subsets are better **only** if the clue remains strong and safe. A clue that connects clearly to 2 words is better than one that weakly connects to 4.

**Your Output:**
Pick **only the best clue**. Response only with a json object containing only the clue’s number (1 through 5) in the following format:
{{
    "choice": "<number 1 through 5>""
}}

"""
    return system_prompt


# In[12]:


class GPTManager():
    def __init__(self, api_key):
        self.openai_client = OpenAI(api_key=api_key)
        self.llm_conversation_history = []

    def talk_to_ai(self, prompt):
        self.llm_conversation_history.append({"role": "user", "content": prompt})
        response = self.openai_client.chat.completions.create(
            messages=self.llm_conversation_history,
            model="gpt-4.1",
            response_format={ "type": "json_object" }
        )
        response = response.choices[0].message.content
        self.llm_conversation_history.append({"role": "assistant", "content": response})
        return response


    def reset_LLM_conversation_history(self):
        self.llm_conversation_history = []

class AICodemaster(Codemaster):
    def __init__(self, team="Red"):
        super().__init__()
        cwd = os.path.dirname(__file__) 
        annoy_path = os.path.join(cwd, "annoy_index")
        self.emb = Annoy(annoy_path=annoy_path)
        self.gpt_manager = GPTManager(api_key=openai_api_key)
        self.team = team
        self.words = []
        self.maps = []
        self.our_words = []
        self.enemy_words = []
        self.civilian_words = []
        self.assassin_word = ""
        self.lemmas = set()
        self.safe_clue_numbers = [1,2]
        self.neutral_clue_numbers = [2]
        self.catchup_clue_numbers = [2,3,4]
        self.equal_clue_numbers = [2,3]
        self.ignore_clue_score = -500.0

    def set_game_state(self, words, maps):
        if len(self.words) == 0 or len(self.maps) == 0:
            self.words = words
            self.maps = maps
            self.update_game_state()

            start = time.time()
            self._init_all_sync()  
            print(f"Time to init hybrid codemaster: {time.time() - start}")

            # All forms of board words
            self.lemmas = set()
            for word in words:
                self.lemmas.update(word)
                self.lemmas.update(get_all_inflections(word))
                self.lemmas.update(get_all_possible_lemmas(word))

        else: 
            self.update_game_state()
            self.words = words
            self.maps = maps

    def update_game_state(self):
        red, blue, civilian, assassin = self.get_remaining_options()
        if self.team.lower() == "red":
            self.our_words, self.enemy_words, self.civilian_words, self.assassin_word = red, blue, civilian, assassin
        else:
            self.our_words, self.enemy_words, self.civilian_words, self.assassin_word = blue, red, civilian, assassin


    def _init_all_sync(self):
        #loop = asyncio.new_event_loop()
        #asyncio.set_event_loop(loop)
        sync_wrapper(self._init_all_async())

    async def _init_all_async(self):
        await asyncio.gather(
            self.init_conceptnet(),
            self.init_llm()
        )

    async def init_conceptnet(self):
        start = time.time()
        self.conceptnet = ConceptNet(self.our_words, self.enemy_words, self.civilian_words, self.assassin_word)
        await self.conceptnet.build_clue_graph()
        if debug:
            print(f"Time to init conceptnet: {time.time() - start}")

    async def init_llm(self):
        start = time.time()
        self.llm_cluemaster = LLM(openai_api_key)
        self.llm_subset_cluemaster = LLM2(openai_api_key)
        self.llm_clues = await self.llm_cluemaster.get_clues_for_words(self.our_words, self.assassin_word)
        if debug:
            print(f"Time to init LLM clues: {time.time() - start}")
            # print("LLM clues: ")
            # for clue_list in self.llm_clues:
            #     print("[+] ", clue_list)


    def get_remaining_options(self):
        # Converts the words and map variables into a more gpt-friendly text format
        red, blue, civilian, assassin = [], [], [], ""
        for i in range(len(self.words)):
            if self.words[i][0] == '*':
                continue
            if self.maps[i] == "Red":
                red.append(self.words[i].lower())
            if self.maps[i] == "Blue":
                blue.append(self.words[i].lower())
            if self.maps[i] == "Civilian":
                civilian.append(self.words[i].lower())
            if self.maps[i] == "Assassin":
                assassin = self.words[i].lower()
        return red, blue, civilian, assassin

    def is_valid_clue(self, word : str):
        """
        return true if a word is NOT a lemma or inflection of any word on the board.
        """
        doc = nlp(word)
        for token in doc:
            if (token.pos_ in allowed_word_types) and (token.lemma_ not in self.lemmas) and (token.text not in self.lemmas):
                return True
        return False

    def get_subset_sizes(self):
        """
        get subset sizes to find clues for depending on the whether we are winning/losing/neutral.
        """
        our_count = 0
        enemy_count = 0
        our_rem = 0
        enemy_rem = 0
        diff = 0
        if self.team.lower() == "red":
            our_count = self.words.count("*Red*")
            our_rem = 9 - our_count
            enemy_count = self.words.count("*Blue*")
            enemy_rem = 8 - enemy_count
        else:
            our_count = self.words.count("*Blue*")
            our_rem = 8 - our_count
            enemy_count = self.words.count("*Red*")
            enemy_rem = 9 - enemy_count
        diff = our_count - enemy_count
        if our_rem == 1:
            return [1]

        if diff <= -1:
            return self.catchup_clue_numbers
        elif diff >= 1:
            if our_rem <= 2:
                return self.safe_clue_numbers
            else:
                return self.neutral_clue_numbers
        else:
            return self.equal_clue_numbers

    def average_pairwise_similarity(self, words):
        if len(words) == 1:
            return 1.0 

        embeddings = self.emb.encode(words)
        sim_matrix = cosine_similarity(embeddings)

        # Extract upper triangle (i < j)
        triu = np.triu_indices(len(words), k=1)
        pairwise_sims = sim_matrix[triu]

        return float(np.mean(pairwise_sims))

    def is_cohesive_subset(self, subset, threshold=0.45):
        return self.average_pairwise_similarity(subset) >= threshold

    def score_clue(self, clue: str, subset: list[str]) -> float:
        clue_emb = self.emb.encode([clue])[0]
        target_embs = self.emb.encode(subset)
        enemy_embs = self.emb.encode(self.enemy_words)
        assassin_emb = self.emb.encode([self.assassin_word])[0]
        assassin_sim = cosine_similarity([clue_emb], [assassin_emb])[0][0]
        target_sims = [cosine_similarity([clue_emb], [e])[0][0] for e in target_embs]

        # ignore clue if it is more similar to assassin than to any target word
        if any(assassin_sim >= sim for sim in target_sims):
            return self.ignore_clue_score

        enemy_sims = [cosine_similarity([clue_emb], [e])[0][0] for e in enemy_embs]
        score = sum(target_sims) - sum(enemy_sims)
        return score


    async def _get_clues_for_subset(self, subset: list[str]):
        """
        Return a tuple: (subset, [clues])
        """
        subset = [word.lower() for word in subset]
        conceptnet_clues = self.conceptnet.find_candidate_clues(subset)
        llm_individual_clues = []
        for target_word, clues in self.llm_clues:
            if target_word.lower() in subset:
                llm_individual_clues += clues
        llm_subset_clues = await self.llm_subset_cluemaster.get_clues_for_words(subset, self.assassin_word)

        merged = set(conceptnet_clues) | set(llm_individual_clues) | set(llm_subset_clues)
        valid = [c for c in merged if self.is_valid_clue(c)]

        clue_scores = []
        for clue in valid:
            score = self.score_clue(clue, subset)
            if score != self.ignore_clue_score:
                clue_scores.append((score, clue))

        # Sort highest score first
        clue_scores.sort(reverse=True)
        return [(score, clue, subset) for score, clue in clue_scores]


    def get_clues_for_subsets(self) -> list:
        """
        for each cohesive subset, get clues for it
        Return a list of tuples. Each tuple has the form (subset, [clues for this subset])
        """
        subset_sizes = self.get_subset_sizes()
        clues_and_subsets = []
        subset_scores = []
        for size in subset_sizes:
            for subset in combinations(self.our_words, size):
                score = self.average_pairwise_similarity(subset)
                if score >= 0.5:
                    subset_scores.append((score, subset))

        # Sort by cohesion score descending
        top_subsets = sorted(subset_scores, key=lambda x: x[0], reverse=True)[:10]

        async def gather_all():
            tasks = [self._get_clues_for_subset(subset) for _, subset in top_subsets]
            return await asyncio.gather(*tasks)

        start = time.time()
        results = sync_wrapper(gather_all())
        if debug:
            print(f"Time taken to score all clues: {time.time() - start}")
            print("All clues: ", results)

        # Flatten 
        all_clue_data = []
        for r in results:
            if r:
                all_clue_data.extend(r)

        # take the top 5 clues
        all_clue_data = sorted(all_clue_data, key=lambda x: x[0], reverse = True)
        if (len(all_clue_data) > 6):
            all_clue_data = all_clue_data[:6]

        # Return in format: (score, clue, subset)
        return all_clue_data

    def LLM_response_to_JSON(self, resp : str) -> dict:
        try:
            resp = json.loads(resp)
            return resp
        except:
            return {}

    def parse_LLM_choice(self, obj: dict) -> int:
        if not obj:
            return 0
        if not "choice" in obj:
            return 0
        try:
            return int(obj["choice"])
        except:
            return 0

    def get_clue(self):
        self.gpt_manager.reset_LLM_conversation_history()
        clues_and_subsets = self.get_clues_for_subsets()

        invalid_timer = 0
        clue = None
        number = None
        red, blue, civilian, assassin = self.get_remaining_options()
        prompt = ""
        start = time.time()
        while clue is None or number is None:
            if invalid_timer == 10:
                clue = "TEST"
                number = 1
                break

            if invalid_timer == 0:
                move_history = ""
                history = self.get_move_history()
                for move in history:
                    if "Codemaster" in move[0]:
                        move_history += move[0] + " gives the clue (" + move[1] + ", " + str(move[2]) + ")"
                    else:
                        move_history += move[0] + " guesses the " + move[2] + " word " + move[1] + " and decided to "
                        if move[3] == True:
                            move_history += "keep guessing"
                        else:
                            move_history += "STOP guessing"
                    move_history += "\n"

                prompt = format_llm_selection_prompt(
                team=self.team,
                enemy="Red" if self.team.lower() == "blue" else "Blue",
                red=red,
                blue=blue,
                civilian=civilian,
                assassin=assassin,
                move_history=move_history,
                clue_candidates=clues_and_subsets
                )
                if debug:
                    print(prompt)
            try:
                res = self.gpt_manager.talk_to_ai(prompt)
                print("LLM's response: ", res)
                res = self.LLM_response_to_JSON(res)
                num = self.parse_LLM_choice(res)
                if debug:
                    print(f"LLM chose the {num}-th clue")

                if num == 0 or num > len(clues_and_subsets):
                    invalid_timer += 1
                    prompt = "Invalid clue. The clue choice must be the between 1 and the number of subsets provided. Your response must follow the provided JSON output format example."
                    continue

                clue, number = clues_and_subsets[num-1][1].upper(), len(clues_and_subsets[num-1][2])

            except:
                invalid_timer += 1
                prompt = "Invalid clue. The clue choice must be the between 1 and the number of subsets provided. Your response must follow the provided JSON output format example."
                continue

        return clue, number


# In[ ]:





# In[ ]:





# In[ ]:




