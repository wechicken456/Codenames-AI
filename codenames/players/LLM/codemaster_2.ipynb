{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92de0e8-a69b-40d5-af18-cd04589eb629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pwnphofun/miniconda3/envs/codenames/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import asyncio\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Download necessary data for WordNetLemmatizer if we haven't already\n",
    "try:\n",
    "    WordNetLemmatizer().lemmatize(\"test\") # Just a test to trigger lookup error if not downloaded\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4') # Open Multilingual Wordnet, often needed for full WordNet functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d1eee-0cf1-4010-8ce0-a4c97494d16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89e206c2-9987-4035-9426-b1eeb36ffdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM2:\n",
    "    def __init__(self, openAI_api_key):\n",
    "        self.client = AsyncOpenAI(api_key=openAI_api_key)\n",
    "\n",
    "        \n",
    "    def _get_word_classes(self, word : str) -> set:\n",
    "        pos_set = set()\n",
    "        for synset in wn.synsets(word):\n",
    "            if synset.name().split('.')[0] != word:\n",
    "                continue  # Only consider exact matches\n",
    "            if synset.pos() == 'n':\n",
    "                pos_set.add('noun')\n",
    "            elif synset.pos() == 'v':\n",
    "                pos_set.add('verb')\n",
    "            elif synset.pos() == 's':\n",
    "                pos_set.add('adj')\n",
    "\n",
    "        if len(pos_set) == 0: pos_set.add('noun') # default to noun if unidentified \n",
    "        return pos_set\n",
    "\n",
    "    def LLM_response_to_JSON(self, resp : str) -> dict:\n",
    "        try:\n",
    "            resp = json.loads(resp)\n",
    "            return resp\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "    def extract_clues_from_LLM_response(self, resp: dict) -> set:\n",
    "        try:\n",
    "            clue_list = resp[\"clues\"]\n",
    "            clues = set()\n",
    "            for clue in clue_list:\n",
    "                clues.add(clue[\"clue\"])\n",
    "            return clues\n",
    "        except:\n",
    "            return set()\n",
    "    \n",
    "    def extract_sentences_from_LLM_response(self, resp: str) -> list[str]:\n",
    "        try:\n",
    "            clue_list = resp[\"clues\"]\n",
    "            sentences = []\n",
    "            for clue in clue_list:\n",
    "                sentences.append(clue[\"example_sentences\"])\n",
    "            return sentences\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "       \n",
    "    \n",
    "    async def get_clues_for_words(self, target_words : str, assassin_word : str) -> list[str]:\n",
    "        words_str = \"[\" + \", \".join(target_words) + \"]\"\n",
    "        prompt = f\"\"\"\n",
    "        **Objective:**\n",
    "        You are a linguistic reasoning assistant helping a Codenames AI Codemaster generate smart, safe, and high-utility clues.\n",
    "        \n",
    "        ## OBJECTIVE\n",
    "        Given the list of target words: [{words_str}], generate **up to 5 distinct one-word clues** that are **strongly related to ALL of the target words**. \n",
    "        Each clue should be:\n",
    "        - A **single English word** (no phrases).\n",
    "        - Strongly and clearly semantically related to **all the target words**. Don't try to be clever - directness is more important.\n",
    "        - Very direct to **all of the target words**. If a clue is indirect to even only 1 of the target words, then it is a bad clue.\n",
    "        - **Safe**, meaning the clue must NOT in anyway relate to the dangerous word \"{assassin_word}\".\n",
    "        - Think like a human: Your reasoning for choosing each clue must connect strongly to commonsense English knowledge such that an average person can understand it - no extremely niche references.\n",
    "        \n",
    "        ## IMPORTANT: Be as quick as you can.\n",
    "\n",
    "        ## RULES\n",
    "        - All clues must be one single English word only.\n",
    "        - All example sentences must clearly show a natural connection between the clue and each target word. \n",
    "        - Do not output anything except the JSON object.\n",
    "\n",
    "        ## Examples\n",
    "         - Examples of good clues: \n",
    "             + clue \"animal\" for target words [\"salmon\", \"chicken\"].\n",
    "             + clue \"superhero\" for target words [\"batman\", \"iron\"]. Because obviously batman is a superhero, and \"ironman\" is a superhero.\n",
    "             + clue \"hogwarts\" for the target words [\"school\", \"spell\", \"lion\"].\n",
    "         - Examples of bad clues:\n",
    "             + clue \"big\" for target words [\"tower\", \"london\"] and assassin word \"stream\". Even if you are aiming for the common connection \"Tower of big ben in London\", the clue \"big\" is too vague and could potentially lead your guesser to guessing the assassin word \"stream\" as a stream can also be big.\n",
    "             + clue \"deer\" for target words [\"buck\", \"bear\", \"robin\"]. Even though these are all animals, they are not strongly related to each other at all except for \"buck\" and \"deer\".  This diverges significantly from how humans often generate and interpret clues for Codenames.\n",
    "             + clue \"mammal\" for target words [\"walrus\", \"bear\", \"eagle\"]. As obviously an eagle is not a mammal. Your clue must strongly relate to ALL of the target words. A much safer and stronger clue is \"animal\".\n",
    "             + clue “djedkare” for target words \"egypt\" and \"king\". Even though it refers to the name of the ruler of Egypt in the 25thcentury B.C., and therefore connects the words “egypt” and “king\", it is so niche that it does not reflect the average person’s knowledge of the English language and is likely to yield random guesses if presented to a human player. \n",
    "             \n",
    "        ## OUTPUT\n",
    "        Respond only with a valid JSON object in the format:\n",
    "        {{\n",
    "          \"clues\": [\n",
    "            {{\n",
    "              \"clue\": \"<one-word clue>\",\n",
    "              \"example_sentences\": [\n",
    "                \"<Example using clue with target word 1>\",\n",
    "                \"<Example using clue with target word 2>\",\n",
    "                \"<Example using clue with target word 3>\"\n",
    "              ]\n",
    "            }},\n",
    "            ...\n",
    "          ]\n",
    "        }}\n",
    "        \n",
    " \n",
    "        \"\"\" \n",
    "        history = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = await self.client.chat.completions.create(\n",
    "            messages=history,\n",
    "            model=\"gpt-5-mini\",\n",
    "            response_format={ \"type\": \"json_object\" }\n",
    "        )\n",
    "        json_res = self.LLM_response_to_JSON(response.choices[0].message.content)\n",
    "        # print(self.extract_sentences_from_LLM_response(json_res))\n",
    "        return self.extract_clues_from_LLM_response(json_res)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9baca05-ccb7-4d3c-9e3d-6487e376e1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92deaa-97b3-48dd-81c1-3f98892bd09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e78ae-8de4-42d1-8f31-67cf3568c389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbfaa9-ed8b-4d4c-859a-9a2c176e57e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b352765-85fc-420d-8656-b7a0f50c67d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86334fc8-58da-47c7-8b42-5fcd2941d031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
