{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db270145-274d-4e00-9c7f-e80ef6462039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pwnphofun/miniconda3/envs/codenames/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import asyncio\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Download necessary data for WordNetLemmatizer if we haven't already\n",
    "try:\n",
    "    WordNetLemmatizer().lemmatize(\"test\") # Just a test to trigger lookup error if not downloaded\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4') # Open Multilingual Wordnet, often needed for full WordNet functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5703a35-3157-47fc-9172-cbbeb22526be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_backup_prompt(our_words : list[str], enemy_words : list[str], civilian_words : list[str], assassin_word: list[str], move_history):\n",
    "    \"\"\"Formats the prompt for the LLM Codemaster backup with more elaborate rules.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an expert Codenames AI Codemaster. Your primary clue generation system has failed to find any suitable clues for the current turn. You must now generate a single high-quality clue from scratch based on the provided game state. Your reasoning must be clear, safe, and based on common knowledge.\n",
    "\n",
    "**Game State:**\n",
    "- **Your Team's Words:** {our_words}\n",
    "- **Enemy Words:** {enemy_words}\n",
    "- **Civilian Words:** {civilian_words}\n",
    "- **Assassin Word:** {assassin_word}\n",
    "\n",
    "**Move History:**\n",
    "{move_history}\n",
    "\n",
    "---\n",
    "**PRINCIPLES FOR GENERATING YOUR CLUE**\n",
    "\n",
    "1.  **Clarity and Commonsense First:** Your reasoning for choosing each clue must connect strongly to commonsense English knowledge. The goal is for an average person to immediately think of the target words when they read your clue.\n",
    "    - **DO NOT** use niche references. Avoid specialized jargon, academic terms, or deep knowledge of specific history, science, or pop culture. Assume the guesser has general knowledge, but not specific expertise.\n",
    "    - **Bad Example:** For 'EGYPT' and 'PYRAMID', the clue 'IMHOTEP' is too niche. A much better clue is 'PHARAOH'.\n",
    "    - **Bad Example:** clue \"Yunnan\" for target word \"China\" is bad, as only a few people around the world really know the geography of China. \"Shanghai\" is a much better clue and a much more well-known name.\n",
    "\n",
    "2.  **Universal Connection to ALL Targets:** The clue's connection must be strong, direct, and equally applicable to EVERY word in your chosen target group. If the connection to even one word is weak, indirect, or requires mental gymnastics, the entire clue is invalid.\n",
    "    - **Bad Example:** For ['WHALE', 'BEAR', 'EAGLE'], the clue 'MAMMAL' is bad because an eagle is a bird, not a mammal. A better clue would be 'ANIMAL'.\n",
    "\n",
    "3.  **Absolute Safety:** The clue must not be related in any way to the enemy words, civilian words, or especially the assassin word. Prioritize safety above all else. If a clue is clever but slightly risky, discard it for a safer one, even if it targets fewer words.\n",
    "\n",
    "---\n",
    "**STRICT RULES**\n",
    "- **ABSOLUTE SAFETY:** Your clue MUST NOT have any connection to the Enemy Words, Civilian Words, or the Assassin Word. A clue that even slightly relates to the assassin word is an instant failure and must be avoided at all costs.\n",
    "- **SINGLE WORD ONLY:** The clue must be a single English word. No phrases, no hyphens, no proper nouns unless they are extremely common (e.g., 'HOLLYWOOD' or 'HOGWARTS').\n",
    "- **NO DERIVED OR CONTAINED FORMS:** The clue cannot be a form of, be a part of, be a substring of, be a tense of, or contain any word currently on the board (your words, enemy words, civilian words, or the assassin). This is a strict rule.\n",
    "    - **Example:** If 'MOON' is on the board, clues like 'MOONLIGHT' or 'HONEYMOON' are illegal.\n",
    "    - **Example:** If 'DRIVE is on the board, 'DROVE' is illegal.\n",
    "\n",
    "---\n",
    "**YOUR TASK**\n",
    "\n",
    "1.  Analyze **Your Team's Words** to find the best possible group of 2 or more related words.\n",
    "2.  Following all principles and rules above, generate the single best clue for that group.\n",
    "3.  Respond ONLY with a valid JSON object containing your chosen clue, the number of words it targets, and the list of words you are targeting.\n",
    "\n",
    "**Output Format Example:**\n",
    "{{\n",
    "  \"clue\": \"FOREST\",\n",
    "  \"number\": 2,\n",
    "  \"target_words\": [\"tree\", \"leaf\"]\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "    \n",
    "\n",
    "class LLMBackup:\n",
    "    def __init__(self, openAI_api_key):\n",
    "        self.client = AsyncOpenAI(api_key=openAI_api_key)\n",
    "\n",
    "    async def get_backup_clue(self, our_words : list[str], enemy_words : list[str], civilian_words : list[str], assassin_word : str, move_history):\n",
    "        \"\"\"\n",
    "        Calls the LLM to generate a clue from scratch when the primary system fails.\n",
    "        \"\"\"\n",
    "        prompt = format_backup_prompt(our_words, enemy_words, civilian_words, assassin_word, move_history)\n",
    "        \n",
    "        try:\n",
    "            response = await self.client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                model=\"gpt-4.1\", # Or your preferred model\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            clue_data = json.loads(content)\n",
    "\n",
    "            clue = clue_data.get(\"clue\", \"PASS\")\n",
    "            number = clue_data.get(\"number\", 1)\n",
    "            target_words = clue_data.get(\"target_words\", our_words)\n",
    "\n",
    "            print(f\"[+] LLMBackup gave clue: ({clue.upper()}, {number}, {target_words})\")\n",
    "            \n",
    "            if not isinstance(clue, str) or not isinstance(number, int) or number < 1:\n",
    "                return \"PASS\", our_words\n",
    "\n",
    "            return clue.upper(), target_words\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[!] LLM Backup Codemaster failed: {e}\")\n",
    "            # If the LLM fails completely, give a safe pass clue.\n",
    "            return \"PASS\", our_words\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
