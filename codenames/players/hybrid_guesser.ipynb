{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01330145-6caa-40fd-b138-890d42310c4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wordnet \u001b[38;5;28;01mas\u001b[39;00m wn\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguesser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Guesser\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLLM\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodemaster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLLM\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodemaster_2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM2\n",
      "\u001b[31mImportError\u001b[39m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import asyncio\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from .guesser import Guesser\n",
    "from .LLM.codemaster import LLM\n",
    "from .LLM.codemaster_2 import LLM2\n",
    "from .conceptnet.conceptnet import ConceptNet\n",
    "from .annoy_index.annoy_index import Annoy\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import lemminflect\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07f2e070-a507-4ffc-ac3a-0e5185e7514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6485ef27-dd97-4e2c-8095-ebcf3d64aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_llm_guesser_prompt(clue: str, num_guesses: int, remaining_words: list[str]) -> str:\n",
    "    \"\"\"Formats the prompt for the LLM guesser fallback.\"\"\"\n",
    "    \n",
    "    words_str = \", \".join(remaining_words)\n",
    "    prompt = f\"\"\"\n",
    "You are an expert Codenames player. Your codemaster has given you a clue. Your task is to determine the most likely target words from the list of words remaining on the board.\n",
    "\n",
    "**Game State:**\n",
    "- **Clue:** \"{clue}\"\n",
    "- **Number of words to guess:** {num_guesses}\n",
    "- **Remaining words on board:** [{words_str}]\n",
    "\n",
    "**Your Task:**\n",
    "1.  Analyze the clue in the context of all the words on the board.\n",
    "2.  Identify the {num_guesses} words that are the strongest and most direct targets for the clue \"{clue}\".\n",
    "3.  Consider common knowledge, wordplay, and semantic relationships.\n",
    "4.  Return your answer as an ordered list, with the most confident guess first.\n",
    "\n",
    "**Output Format:**\n",
    "Respond ONLY with a valid JSON object. The object should contain a single key, \"guesses\", which holds a list of your chosen words in order.\n",
    "\n",
    "**Example:**\n",
    "If the clue is \"ANIMAL 2\" and you choose \"lion\" and \"tiger\", your output should be:\n",
    "{{\n",
    "  \"guesses\": [\"lion\", \"tiger\"]\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "class GPTManager():\n",
    "    def __init__(self, api_key):\n",
    "        self.openai_client = OpenAI(api_key=api_key)\n",
    "        self.llm_conversation_history = []\n",
    "\n",
    "    def talk_to_ai(self, prompt):\n",
    "        self.llm_conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            messages=self.llm_conversation_history,\n",
    "            model=\"gpt-5-mini\",\n",
    "            response_format={ \"type\": \"json_object\" }\n",
    "        )\n",
    "        response = response.choices[0].message.content\n",
    "        self.llm_conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "\n",
    "\n",
    "    def reset_LLM_conversation_history(self):\n",
    "        self.llm_conversation_history = []\n",
    "        \n",
    "\n",
    "class AIGuesser(Guesser):\n",
    "    def __init__(self, team=\"Red\"):\n",
    "        super().__init__()\n",
    "        cwd = os.path.dirname(__file__) \n",
    "        annoy_path = os.path.join(cwd, \"annoy_index\")\n",
    "        self.emb = Annoy(annoy_path=annoy_path)\n",
    "        self.gpt_manager = GPTManager(api_key=openai_api_key)\n",
    "\n",
    "        # Game state\n",
    "        self.team = team\n",
    "        self.board_words = []\n",
    "        self.clue = None\n",
    "        self.num_guesses = 0\n",
    "\n",
    "        # Internal strategy variables\n",
    "        self.planned_guesses = []\n",
    "        self.turn_in_progress = False\n",
    "\n",
    "        self.w_fitness = 0.7\n",
    "        self.w_cohesion = 0.3\n",
    "        self.CONFIDENCE_THRESHOLD = 0.45 # minimum score for subset to be considered to use as guesses \n",
    "\n",
    "    def set_board(self, words_on_board: list[str]):\n",
    "        self.board_words = [word.lower() for word in words_on_board]\n",
    "\n",
    "    def set_clue(self, clue: str, num_guesses: int):\n",
    "        self.clue = clue.lower()\n",
    "        self.num_guesses = num_guesses\n",
    "        self.turn_in_progress = True\n",
    "\n",
    "        remaining_words = [word for word in self.board_words if '*' not in word]\n",
    "        self._formulate_plan(remaining_words)\n",
    "\n",
    "    def get_answer(self) -> str:\n",
    "        if self.planned_guesses:\n",
    "            next_guess = self.planned_guesses.pop(0)\n",
    "            if not self.planned_guesses:\n",
    "                self.turn_in_progress = False\n",
    "            return next_guess.upper()\n",
    "\n",
    "        self.turn_in_progress = False\n",
    "        return \"\"\n",
    "\n",
    "    def keep_guessing(self) -> bool:\n",
    "        return self.turn_in_progress and len(self.planned_guesses) > 0\n",
    "\n",
    "    def get_answer(self):\n",
    "        if self.planned_guesses:\n",
    "            next_guess = self.planned_guesses.pop(0)\n",
    "            if not self.planned_guesses:\n",
    "                self.turn_in_progress = False\n",
    "            return next_guess.upper()\n",
    "\n",
    "        self.turn_in_progress = False\n",
    "        return \"\"\n",
    "\n",
    "    def _score_subset(self, subset: tuple[str], clue_word_sims: dict[str, float]) -> float:\n",
    "        fitness_score = np.mean([clue_word_sims[word] for word in subset])\n",
    "        cohesion_score = self.average_pairwise_similarity(list(subset))\n",
    "        return float((self.w_fitness * fitness_score) + (self.w_cohesion * cohesion_score))\n",
    "\n",
    "    def _formulate_plan(self, remaining_words: list[str]):\n",
    "        if not self.clue or self.num_guesses == 0:\n",
    "            self.planned_guesses = []\n",
    "            return\n",
    "\n",
    "        clue_emb = self.emb.encode([self.clue])[0]\n",
    "        remaining_embs = self.emb.encode(remaining_words)\n",
    "        sims = cosine_similarity([clue_emb], remaining_embs)[0]\n",
    "        clue_word_sims = {word: sim for word, sim in zip(remaining_words, sims)}\n",
    "\n",
    "        num_to_find = min(self.num_guesses, len(remaining_words))\n",
    "        if num_to_find == 0:\n",
    "            self.planned_guesses = []; return\n",
    "\n",
    "        best_subset = None\n",
    "        max_score = -np.inf\n",
    "\n",
    "        if num_to_find == 1:\n",
    "            best_word = max(clue_word_sims, key=clue_word_sims.get)\n",
    "            best_subset = (best_word,)\n",
    "            # Score for a single word is just its similarity to the clue.\n",
    "            max_score = clue_word_sims[best_word]\n",
    "        else:\n",
    "            candidate_subsets = combinations(remaining_words, num_to_find)\n",
    "            for subset in candidate_subsets:\n",
    "                score = self._score_subset(subset, clue_word_sims)\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    best_subset = subset\n",
    "\n",
    "        # Confidence check. Fall back to asking LLM to select words.\n",
    "        if max_score < self.CONFIDENCE_THRESHOLD or best_subset is None:\n",
    "            print(f\"[!] Low confidence (score: {max_score:.3f}). Falling back to LLM...\")\n",
    "            self.planned_guesses = self._get_guesses_from_llm(remaining_words)\n",
    "        else:\n",
    "            ordered_guesses = sorted(list(best_subset), key=lambda w: clue_word_sims[w], reverse=True)\n",
    "            self.planned_guesses = ordered_guesses\n",
    "\n",
    "    def _get_guesses_from_llm(self, remaining_words: list[str]) -> list[str]:\n",
    "        \"\"\"Calls the LLM to get guesses when the vector model is not confident.\"\"\"\n",
    "        try:\n",
    "            prompt = format_llm_guesser_prompt(self.clue, self.num_guesses, remaining_words)\n",
    "            response_str = self.gpt_manager.talk_to_ai(prompt)\n",
    "            response_json = json.loads(response_str)\n",
    "            guesses = response_json.get(\"guesses\", [])\n",
    "            valid_guesses = [g.lower() for g in guesses if g.lower() in remaining_words]\n",
    "            return valid_guesses[:self.num_guesses]\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] LLM Fallback: {e}\")\n",
    "            # More fallback: just guess the most similar words if LLM fails\n",
    "            return sorted(remaining_words, key=lambda w: cosine_similarity(self.emb.encode([self.clue]), self.emb.encode([w]))[0][0], reverse=True)[:self.num_guesses]\n",
    "\n",
    "\n",
    "    def average_pairwise_similarity(self, words: list[str]) -> float:\n",
    "        if len(words) < 2: \n",
    "            return 1.0 \n",
    "        embeddings = self.emb.encode(words)\n",
    "        sim_matrix = cosine_similarity(embeddings)\n",
    "        triu_indices = np.triu_indices(len(words), k=1)\n",
    "        pairwise_sims = sim_matrix[triu_indices]\n",
    "        return float(np.mean(pairwise_sims)) if pairwise_sims.size > 0 else 0.0\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1599010-2160-4424-b35e-de275e80f878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2eca7-0171-49b2-95f3-8ea9818d54f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
