{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefe75e8-22b1-4a21-a7c0-5cbfa19b4ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pwnphofun/miniconda3/envs/codenames/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wordnet \u001b[38;5;28;01mas\u001b[39;00m wn\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodemaster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Codemaster\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLLM\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodemaster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLLM\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodemaster_2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM2\n",
      "\u001b[31mImportError\u001b[39m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import asyncio\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from .codemaster import Codemaster\n",
    "from .LLM.codemaster import LLM\n",
    "from .LLM.codemaster_2 import LLM2\n",
    "from .conceptnet.conceptnet import ConceptNet\n",
    "from .annoy_index.annoy_index import Annoy\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import lemminflect\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9e64c5-ca2e-401b-86f3-fc069c4dca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775b8761-d5df-4473-9976-cce7a23803c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ba05fd-7c22-4ac1-bcf0-0e38a2576440",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_word_types = [\n",
    "    \"ADJ\",\t\n",
    "    \"ADV\",\n",
    "    \"INTJ\",\t\n",
    "    \"NOUN\",\n",
    "    \"PROPN\",\t\n",
    "    \"VERB\"\n",
    "]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def get_word_lemma(word : str, pos_hint : str = None) -> str:\n",
    "    \"\"\"\n",
    "    Gets the lemma of a single word without sentence context using NLTK's WordNetLemmatizer.\n",
    "    pos_hint can be 'n' (noun), 'v' (verb), 'a' (adjective), 'r' (adverb).\n",
    "    Defaults to 'n' if no hint is given.\n",
    "    \"\"\"\n",
    "    return lemmatizer.lemmatize(word.lower(), pos=pos_hint) if pos_hint else lemmatizer.lemmatize(word.lower())\n",
    "\n",
    "def get_all_possible_lemmas(word: str) -> list[str]:\n",
    "    res = []\n",
    "    for hint in [\"v\", \"n\", \"a\", \"r\", \"s\"]:\n",
    "        res.append(get_word_lemma(word, hint))\n",
    "    return res\n",
    "\n",
    "def get_all_inflections(word : str) -> list[str]:\n",
    "    inflections = lemminflect.getAllInflections(word)\n",
    "    res = []\n",
    "    for _, i in inflections.items():\n",
    "        res += list(i)\n",
    "    return res\n",
    "\n",
    "def sync_wrapper(coro):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return loop.run_until_complete(coro)\n",
    "\n",
    "\n",
    "def format_llm_selection_prompt(team, enemy, red, blue, civilian, assassin, move_history, clue_candidates):\n",
    "    system_prompt = f\"\"\"\n",
    "You are a human that plays the game Codenames using common knowledge, clarity, and reasoning. \n",
    "\n",
    "**Task:**\n",
    "You are given the current state of the game and a list of possible clues (not in any particular order) generated by a teammate. Each clue is intended to target a specific subset of your team's words. Your job is to **select the best clue to give to your guessers**, based on the provided principles of clue quality and safety.\n",
    "\n",
    "**Game State:**\n",
    "- Your team: {team}\n",
    "- Your remaining words: {red if team.lower() == 'red' else blue}\n",
    "- Enemy remaining words: {blue if team.lower() == 'red' else red}\n",
    "- Civilian remaining words: {civilian}\n",
    "- Assassin word: {assassin}\n",
    "\n",
    "**Move History:**\n",
    "{move_history}\n",
    "\n",
    "**Candidate Clues:**\n",
    "Each candidate clue was automatically generated. All clues are single English words and attempt to connect semantically with the listed target words.\n",
    "The clues are listed in no particular order.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    for i, (score, clue, subset) in enumerate(clue_candidates):\n",
    "        system_prompt += f\"{i+1}. Clue: \\\"{clue}\\\" — Targets: {subset} — Number of targets: {len(subset)}\\n\"\n",
    "\n",
    "    system_prompt += f\"\"\"\n",
    "\n",
    "**Your Clue Selection Strategy:**\n",
    "\n",
    "1. **Clarity and Immediate Understandability**\n",
    "   - The clue must connect strongly and obviously to its target words.\n",
    "   - Avoid niche or obscure or indirect associations.\n",
    "\n",
    "2. **Strict Rule Compliance**\n",
    "   - Clue must not be a form or compound of any word on the board.\n",
    "   - Must be a single word (not a phrase or name).\n",
    "   - Must not rely on uncommon or culturally niche knowledge.\n",
    "\n",
    "3. **Avoiding the Assassin Word**\n",
    "   - If **any clue even loosely relates** to the assassin word, it must be disqualified.\n",
    "\n",
    "4. **Minimizing Risk**\n",
    "   - Prefer clues with minimal semantic overlap with enemy or civilian words.\n",
    "\n",
    "5. **Think like a human player**\n",
    "   - Avoid clues that require expert knowledge or unusual interpretations.\n",
    "\n",
    "6. **Subset Size Awareness**\n",
    "   - Bigger subsets are better **only** if the clue remains strong and safe. A clue that connects clearly to 2 words is better than one that weakly connects to 4.\n",
    "\n",
    "**Your Output:**\n",
    "Pick **only the best clue**. Response only with a json object containing only the clue’s number (1 through 5) in the following format:\n",
    "{{\n",
    "    \"choice\": \"<number 1 through 5>\"\"\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "    return system_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61c4a18-8546-4452-9b1b-3db08c26f574",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Codemaster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset_LLM_conversation_history\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     19\u001b[39m         \u001b[38;5;28mself\u001b[39m.llm_conversation_history = []\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAICodemaster\u001b[39;00m(\u001b[43mCodemaster\u001b[49m):\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, team=\u001b[33m\"\u001b[39m\u001b[33mRed\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     23\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'Codemaster' is not defined"
     ]
    }
   ],
   "source": [
    "class GPTManager():\n",
    "    def __init__(self, api_key):\n",
    "        self.openai_client = OpenAI(api_key=api_key)\n",
    "        self.llm_conversation_history = []\n",
    "\n",
    "    def talk_to_ai(self, prompt):\n",
    "        self.llm_conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            messages=self.llm_conversation_history,\n",
    "            model=\"gpt-5-mini\",\n",
    "            response_format={ \"type\": \"json_object\" }\n",
    "        )\n",
    "        response = response.choices[0].message.content\n",
    "        self.llm_conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "\n",
    "\n",
    "    def reset_LLM_conversation_history(self):\n",
    "        self.llm_conversation_history = []\n",
    "\n",
    "class AICodemaster(Codemaster):\n",
    "    def __init__(self, team=\"Red\"):\n",
    "        super().__init__()\n",
    "        cwd = os.path.dirname(__file__) \n",
    "        annoy_path = os.path.join(cwd, \"annoy_index\")\n",
    "        self.emb = Annoy(annoy_path=annoy_path)\n",
    "        self.gpt_manager = GPTManager(api_key=openai_api_key)\n",
    "        self.team = team\n",
    "        self.words = []\n",
    "        self.maps = []\n",
    "        self.our_words = []\n",
    "        self.enemy_words = []\n",
    "        self.civilian_words = []\n",
    "        self.assassin_word = \"\"\n",
    "        self.lemmas = set()\n",
    "        self.safe_clue_numbers = [1,2]\n",
    "        self.neutral_clue_numbers = [2]\n",
    "        self.catchup_clue_numbers = [2,3,4]\n",
    "        self.equal_clue_numbers = [1,2,3]\n",
    "        self.ignore_clue_score = -500.0\n",
    "\n",
    "    def set_game_state(self, words, maps):\n",
    "        if len(self.words) == 0 or len(self.maps) == 0:\n",
    "            self.words = words\n",
    "            self.maps = maps\n",
    "            self.update_game_state()\n",
    "\n",
    "            start = time.time()\n",
    "            self._init_all_sync()  \n",
    "            print(f\"Time to init hybrid codemaster: {time.time() - start}\")\n",
    "\n",
    "            # All forms of board words\n",
    "            self.lemmas = set()\n",
    "            for word in words:\n",
    "                self.lemmas.update(word)\n",
    "                self.lemmas.update(get_all_inflections(word))\n",
    "                self.lemmas.update(get_all_possible_lemmas(word))\n",
    "\n",
    "        else: \n",
    "            self.words = words\n",
    "            self.maps = maps\n",
    "            self.update_game_state()\n",
    "\n",
    "\n",
    "    def update_game_state(self):\n",
    "        red, blue, civilian, assassin = self.get_remaining_options()\n",
    "        if self.team.lower() == \"red\":\n",
    "            self.our_words, self.enemy_words, self.civilian_words, self.assassin_word = red, blue, civilian, assassin\n",
    "        else:\n",
    "            self.our_words, self.enemy_words, self.civilian_words, self.assassin_word = blue, red, civilian, assassin\n",
    "\n",
    "\n",
    "    def _init_all_sync(self):\n",
    "        #loop = asyncio.new_event_loop()\n",
    "        #asyncio.set_event_loop(loop)\n",
    "        sync_wrapper(self._init_all_async())\n",
    "\n",
    "    async def _init_all_async(self):\n",
    "        await asyncio.gather(\n",
    "            self.init_conceptnet(),\n",
    "            self.init_llm()\n",
    "        )\n",
    "\n",
    "    async def init_conceptnet(self):\n",
    "        start = time.time()\n",
    "        self.conceptnet = ConceptNet(self.our_words, self.enemy_words, self.civilian_words, self.assassin_word)\n",
    "        await self.conceptnet.build_clue_graph()\n",
    "        if debug:\n",
    "            print(f\"Time to init conceptnet: {time.time() - start}\")\n",
    "\n",
    "    async def init_llm(self):\n",
    "        start = time.time()\n",
    "        self.llm_cluemaster = LLM(openai_api_key)\n",
    "        self.llm_subset_cluemaster = LLM2(openai_api_key)\n",
    "        self.llm_clues = await self.llm_cluemaster.get_clues_for_words(self.our_words, self.assassin_word)\n",
    "        if debug:\n",
    "            print(f\"Time to init LLM clues: {time.time() - start}\")\n",
    "            # print(\"LLM clues: \")\n",
    "            # for clue_list in self.llm_clues:\n",
    "            #     print(\"[+] \", clue_list)\n",
    "\n",
    "\n",
    "    def get_remaining_options(self):\n",
    "        # Converts the words and map variables into a more gpt-friendly text format\n",
    "        red, blue, civilian, assassin = [], [], [], \"\"\n",
    "        for i in range(len(self.words)):\n",
    "            if self.words[i][0] == '*':\n",
    "                continue\n",
    "            if self.maps[i] == \"Red\":\n",
    "                red.append(self.words[i].lower())\n",
    "            if self.maps[i] == \"Blue\":\n",
    "                blue.append(self.words[i].lower())\n",
    "            if self.maps[i] == \"Civilian\":\n",
    "                civilian.append(self.words[i].lower())\n",
    "            if self.maps[i] == \"Assassin\":\n",
    "                assassin = self.words[i].lower()\n",
    "        return red, blue, civilian, assassin\n",
    "\n",
    "    def is_valid_clue(self, word : str):\n",
    "        \"\"\"\n",
    "        return true if a word is NOT a lemma or inflection of any word on the board.\n",
    "        \"\"\"\n",
    "        doc = nlp(word)\n",
    "        for token in doc:\n",
    "            if (token.pos_ in allowed_word_types) and (token.lemma_ not in self.lemmas) and (token.text not in self.lemmas):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_subset_sizes(self):\n",
    "        \"\"\"\n",
    "        get subset sizes to find clues for depending on the whether we are winning/losing/neutral.\n",
    "        \"\"\"\n",
    "        our_count = 0\n",
    "        enemy_count = 0\n",
    "        our_rem = 0\n",
    "        enemy_rem = 0\n",
    "        diff = 0\n",
    "        if self.team.lower() == \"red\":\n",
    "            our_count = self.words.count(\"*Red*\")\n",
    "            our_rem = 9 - our_count\n",
    "            enemy_count = self.words.count(\"*Blue*\")\n",
    "            enemy_rem = 8 - enemy_count\n",
    "        else:\n",
    "            our_count = self.words.count(\"*Blue*\")\n",
    "            our_rem = 8 - our_count\n",
    "            enemy_count = self.words.count(\"*Red*\")\n",
    "            enemy_rem = 9 - enemy_count\n",
    "        diff = our_count - enemy_count\n",
    "        if our_rem == 1:\n",
    "            return [1]\n",
    "\n",
    "        if diff <= -1:\n",
    "            return self.catchup_clue_numbers\n",
    "        elif diff >= 1:\n",
    "            if our_rem <= 2:\n",
    "                return self.safe_clue_numbers\n",
    "            else:\n",
    "                return self.neutral_clue_numbers\n",
    "        else:\n",
    "            return self.equal_clue_numbers\n",
    "\n",
    "    def average_pairwise_similarity(self, words):\n",
    "        if len(words) < 2:\n",
    "            return 1.0 \n",
    "\n",
    "        embeddings = self.emb.encode(words)\n",
    "        sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "        # Extract upper triangle (i < j)\n",
    "        triu = np.triu_indices(len(words), k=1)\n",
    "        pairwise_sims = sim_matrix[triu]\n",
    "\n",
    "        return float(np.mean(pairwise_sims))\n",
    "\n",
    "    def is_cohesive_subset(self, subset, threshold=0.45):\n",
    "        return self.average_pairwise_similarity(subset) >= threshold\n",
    "\n",
    "    def score_clue(self, clue: str, subset: list[str]) -> float:\n",
    "        \"\"\"\n",
    "        Score a clue against a subset of target words, enemy words, and assassin word.\n",
    "        1.  the clue is immediately discarded if it is more similar to the assassin or the top enemy word than it is to its weakest target word. Return self.ignore_clue_score\n",
    "        2.  Positive Score: Calculated from a weighted sum of the clue's:\n",
    "            - Average similarity to all target words (for overall strength).\n",
    "            - Minimum similarity to any target word (to reward consistency and\n",
    "              penalize high variance, ensuring the clue works for all words).\n",
    "        3.  Penalty Score: A weighted penalty based on the clue's similarity to the most dangerous non-target words:\n",
    "            - The single *most similar* enemy word.\n",
    "            - The single *most similar* civilian word.\n",
    "            - The assassin word (very high penalty).    \n",
    "        4.  Subset Size Bonus: A small logarithmic bonus is added for clues\n",
    "            that target more words, giving diminishing returns for larger groups.\n",
    "\n",
    "        \"\"\"\n",
    "        W_AVG_TARGET = 0.6\n",
    "        W_MIN_TARGET = 0.4\n",
    "        W_ENEMY_MAX = 0.5\n",
    "        W_CIVILIAN_MAX = 0.3\n",
    "        W_ASSASSIN = 2\n",
    "        print(f\"scoring clue {clue} against subset {subset}\")\n",
    "        clue_emb = self.emb.encode([clue])[0]\n",
    "\n",
    "        target_embs = self.emb.encode(subset)\n",
    "        print(\"clue_emb: \", clue_emb)\n",
    "        print(\"target_embs: \", target_embs)\n",
    "        target_sims = cosine_similarity([clue_emb], target_embs)[0]\n",
    "\n",
    "        enemy_sims = np.array([])\n",
    "        if self.enemy_words:\n",
    "            enemy_embs = self.emb.encode(self.enemy_words)\n",
    "            enemy_sims = cosine_similarity([clue_emb], enemy_embs)[0]\n",
    "\n",
    "        civilian_sims = np.array([])\n",
    "        if self.civilian_words:\n",
    "            civilian_embs = self.emb.encode(self.civilian_words)\n",
    "            civilian_sims = cosine_similarity([clue_emb], civilian_embs)[0]\n",
    "\n",
    "        assassin_sim = 0.0\n",
    "        if self.assassin_word:\n",
    "            assassin_emb = self.emb.encode([self.assassin_word])[0]\n",
    "            assassin_sim = cosine_similarity([clue_emb], [assassin_emb])[0][0]\n",
    "\n",
    "        min_target_sim = np.min(target_sims)\n",
    "        max_enemy_sim = np.max(enemy_sims) if enemy_sims.size > 0 else 0.0\n",
    "\n",
    "        if assassin_sim + 0.1 >= min_target_sim or assassin_sim > 0.35:\n",
    "            return self.ignore_clue_score\n",
    "\n",
    "        if max_enemy_sim + 0.1 >= min_target_sim:\n",
    "            return self.ignore_clue_score\n",
    "\n",
    "        avg_target_sim = np.mean(target_sims)\n",
    "        positive_score = (W_AVG_TARGET * avg_target_sim) + (W_MIN_TARGET * min_target_sim)\n",
    "\n",
    "        max_civilian_sim = np.max(civilian_sims) if civilian_sims.size > 0 else 0.0\n",
    "\n",
    "        penalty_score = (W_ENEMY_MAX * max_enemy_sim) + \\\n",
    "                        (W_CIVILIAN_MAX * max_civilian_sim) + \\\n",
    "                        (W_ASSASSIN * assassin_sim)\n",
    "\n",
    "        final_score = positive_score - penalty_score\n",
    "\n",
    "        # larger subsets will have diminishing returns\n",
    "        score_boost = 0.1 * np.log(len(subset)) if len(subset) > 1 else 0\n",
    "        final_score += score_boost\n",
    "\n",
    "        return final_score\n",
    "\n",
    "    async def _get_clues_for_subset(self, subset: list[str]):\n",
    "        \"\"\"\n",
    "        Return a tuple: (subset, [clues])\n",
    "        \"\"\"\n",
    "        subset = [word.lower() for word in subset]\n",
    "        conceptnet_clues = self.conceptnet.find_candidate_clues(subset)\n",
    "        llm_individual_clues = []\n",
    "        for target_word, clues in self.llm_clues:\n",
    "            if target_word.lower() in subset:\n",
    "                llm_individual_clues += clues\n",
    "        llm_subset_clues = await self.llm_subset_cluemaster.get_clues_for_words(subset, self.assassin_word)\n",
    "\n",
    "        merged = set(conceptnet_clues) | set(llm_individual_clues) | set(llm_subset_clues)\n",
    "        valid = [c for c in merged if self.is_valid_clue(c)]\n",
    "\n",
    "        clue_scores = []\n",
    "        for clue in valid:\n",
    "            score = self.score_clue(clue, subset)\n",
    "            if score != self.ignore_clue_score:\n",
    "                clue_scores.append((score, clue))\n",
    "\n",
    "        # Sort highest score first\n",
    "        clue_scores.sort(reverse=True)\n",
    "        return [(score, clue, subset) for score, clue in clue_scores]\n",
    "\n",
    "\n",
    "    def get_clues_for_subsets(self) -> list:\n",
    "        \"\"\"\n",
    "        for each cohesive subset, get clues for it\n",
    "        Return a list of tuples. Each tuple has the form (subset, [clues for this subset])\n",
    "        \"\"\"\n",
    "        subset_sizes = self.get_subset_sizes()\n",
    "        clues_and_subsets = []\n",
    "        subset_scores = []\n",
    "        for size in subset_sizes:\n",
    "            for subset in combinations(self.our_words, size):\n",
    "                score = self.average_pairwise_similarity(subset)\n",
    "                if score >= 0.4:\n",
    "                    subset_scores.append((score, subset))\n",
    "\n",
    "        # Sort by cohesion score descending\n",
    "        top_subsets = sorted(subset_scores, key=lambda x: x[0], reverse=True)[:8]\n",
    "        if len(top_subsets) == 0:\n",
    "            top_subsets = [(1.0, [word]) for word in self.our_words]\n",
    "\n",
    "        async def gather_all():\n",
    "            tasks = [self._get_clues_for_subset(subset) for _, subset in top_subsets]\n",
    "            return await asyncio.gather(*tasks)\n",
    "\n",
    "        start = time.time()\n",
    "        results = sync_wrapper(gather_all())\n",
    "        if debug:\n",
    "            print(f\"Time taken to score all clues: {time.time() - start}\")\n",
    "            print(\"All clues: \", results)\n",
    "\n",
    "        # Flatten \n",
    "        all_clue_data = []\n",
    "        for r in results:\n",
    "            if r:\n",
    "                all_clue_data.extend(r)\n",
    "\n",
    "        # take the top 5 clues\n",
    "        all_clue_data = sorted(all_clue_data, key=lambda x: x[0], reverse = True)\n",
    "        if (len(all_clue_data) > 6):\n",
    "            all_clue_data = all_clue_data[:6]\n",
    "\n",
    "        # Return in format: (score, clue, subset)\n",
    "        return all_clue_data\n",
    "\n",
    "    def LLM_response_to_JSON(self, resp : str) -> dict:\n",
    "        try:\n",
    "            resp = json.loads(resp)\n",
    "            return resp\n",
    "        except:\n",
    "            if debug:\n",
    "                print(\"[!] parse_LLM_choice: Invalid LLM response\")\n",
    "            return {}\n",
    "\n",
    "    def parse_LLM_choice(self, obj: dict) -> int:\n",
    "        if not obj:\n",
    "            return 0\n",
    "        if not \"choice\" in obj:\n",
    "            return 0\n",
    "        try:\n",
    "            return int(obj[\"choice\"])\n",
    "        except:\n",
    "            if debug:\n",
    "                print(\"[!] parse_LLM_choice: Invalid LLM choice\")\n",
    "            return 0\n",
    "\n",
    "    def get_clue(self):\n",
    "        self.gpt_manager.reset_LLM_conversation_history()\n",
    "        clues_and_subsets = self.get_clues_for_subsets()\n",
    "\n",
    "        invalid_timer = 0\n",
    "        clue = None\n",
    "        number = None\n",
    "        red, blue, civilian, assassin = self.get_remaining_options()\n",
    "        prompt = \"\"\n",
    "        start = time.time()\n",
    "        while clue is None or number is None:\n",
    "            if invalid_timer == 10:\n",
    "                clue = \"TEST\"\n",
    "                number = 1\n",
    "                break\n",
    "\n",
    "            if invalid_timer == 0:\n",
    "                move_history = \"\"\n",
    "                history = self.get_move_history()\n",
    "                for move in history:\n",
    "                    if \"Codemaster\" in move[0]:\n",
    "                        move_history += move[0] + \" gives the clue (\" + move[1] + \", \" + str(move[2]) + \")\"\n",
    "                    else:\n",
    "                        move_history += move[0] + \" guesses the \" + move[2] + \" word \" + move[1] + \" and decided to \"\n",
    "                        if move[3] == True:\n",
    "                            move_history += \"keep guessing\"\n",
    "                        else:\n",
    "                            move_history += \"STOP guessing\"\n",
    "                    move_history += \"\\n\"\n",
    "\n",
    "                prompt = format_llm_selection_prompt(\n",
    "                team=self.team,\n",
    "                enemy=\"Red\" if self.team.lower() == \"blue\" else \"Blue\",\n",
    "                red=red,\n",
    "                blue=blue,\n",
    "                civilian=civilian,\n",
    "                assassin=assassin,\n",
    "                move_history=move_history,\n",
    "                clue_candidates=clues_and_subsets\n",
    "                )\n",
    "                if debug:\n",
    "                    print(prompt)\n",
    "            try:\n",
    "                res = self.gpt_manager.talk_to_ai(prompt)\n",
    "                print(\"LLM's response: \", res)\n",
    "                res = self.LLM_response_to_JSON(res)\n",
    "                num = self.parse_LLM_choice(res)\n",
    "                if debug:\n",
    "                    print(f\"LLM chose the {num}-th clue\")\n",
    "\n",
    "                if num == 0 or num > len(clues_and_subsets):\n",
    "                    invalid_timer += 1\n",
    "                    prompt = \"Invalid clue. The clue choice must be the between 1 and the number of subsets provided. Your response must follow the provided JSON output format example.\"\n",
    "                    continue\n",
    "\n",
    "                clue, number = clues_and_subsets[num-1][1].upper(), len(clues_and_subsets[num-1][2])\n",
    "\n",
    "            except:\n",
    "                invalid_timer += 1\n",
    "                prompt = \"Invalid clue. The clue choice must be the between 1 and the number of subsets provided. Your response must follow the provided JSON output format example.\"\n",
    "                continue\n",
    "\n",
    "        return clue, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34554817-f451-4b25-b24b-dcdcb85d41dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2588d-e04f-4262-a6e6-f7e58484dea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a553c-b880-432d-8383-aead53e66731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
